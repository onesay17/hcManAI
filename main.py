"""
hcManAi - AI ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤
FastAPIë¥¼ ì‚¬ìš©í•œ REST API ì„œë²„
"""
from fastapi import FastAPI, HTTPException, Request
from fastapi.exceptions import RequestValidationError
from fastapi.responses import JSONResponse
from pydantic import BaseModel, field_validator, model_validator
from typing import Optional
import uvicorn
import json
from rag_service import RAGService
from llm_service import LLMService
from config import settings


app = FastAPI(
    title="hcManAi",
    description="AI ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ - Text-to-SQL ë° ë°ì´í„° ìš”ì•½",
    version="1.0.0"
)

# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
rag_service: Optional[RAGService] = None
llm_service: Optional[LLMService] = None


@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    global rag_service, llm_service
    try:
        rag_service = RAGService()
        llm_service = LLMService()
        print("âœ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise


@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """ìš”ì²­ ìœ íš¨ì„± ê²€ì¦ ì˜¤ë¥˜ í•¸ë“¤ëŸ¬"""
    print(f"âŒ ìš”ì²­ ìœ íš¨ì„± ê²€ì¦ ì‹¤íŒ¨:")
    print(f"   URL: {request.url}")
    print(f"   Method: {request.method}")
    try:
        body = await request.body()
        print(f"   ìš”ì²­ ë³¸ë¬¸: {body.decode('utf-8')}")
    except Exception as e:
        print(f"   ìš”ì²­ ë³¸ë¬¸ ì½ê¸° ì‹¤íŒ¨: {e}")
    print(f"   ì˜¤ë¥˜ ìƒì„¸: {exc.errors()}")
    
    # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
    errors = []
    for error in exc.errors():
        error_dict = {
            "type": error.get("type"),
            "loc": error.get("loc"),
            "msg": error.get("msg"),
            "input": error.get("input")
        }
        # ctxì— ìˆëŠ” error ê°ì²´ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
        if "ctx" in error and "error" in error["ctx"]:
            error_dict["ctx"] = {"error": str(error["ctx"]["error"])}
        errors.append(error_dict)
    
    return JSONResponse(
        status_code=422,
        content={"detail": errors}
    )


# Request/Response ëª¨ë¸
class GenerateSQLRequest(BaseModel):
    query: str


class GenerateSQLResponse(BaseModel):
    sql: str


class SummarizeRequest(BaseModel):
    query: str
    data: str


class SummarizeResponse(BaseModel):
    response: str


class ChatRequest(BaseModel):
    question: str


class ChatResponse(BaseModel):
    answer: str


class QueryRequest(BaseModel):
    """í†µí•© ì§ˆë¬¸ ìš”ì²­ ëª¨ë¸"""
    question: str


class QueryResponse(BaseModel):
    """í†µí•© ì§ˆë¬¸ ì‘ë‹µ ëª¨ë¸"""
    question_type: str  # "schema" ë˜ëŠ” "general"
    sql: Optional[str] = None  # ìŠ¤í‚¤ë§ˆ ì§ˆë¬¸ì¸ ê²½ìš° SQL
    answer: Optional[str] = None  # ì¼ë°˜ ì§ˆë¬¸ì¸ ê²½ìš° ë‹µë³€


class ClassifyQueryRequest(BaseModel):
    """ì§ˆë¬¸ ë¶„ë¥˜ ìš”ì²­ ëª¨ë¸
    
    ë°±ì—”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´ ë‹¤ìŒ í•„ë“œë“¤ì„ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤:
    - question: ë°±ì—”ë“œì—ì„œ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” í•„ë“œëª…
    - query: ëŒ€ì²´ í•„ë“œëª…
    - message: ëŒ€ì²´ í•„ë“œëª…
    - data: SQL ì‹¤í–‰ ê²°ê³¼ ë°ì´í„° (JSON ë¬¸ìì—´, ì„ íƒì‚¬í•­)
    """
    question: Optional[str] = None
    query: Optional[str] = None
    message: Optional[str] = None
    data: Optional[str] = None  # SQL ì‹¤í–‰ ê²°ê³¼ ë°ì´í„° (REPORT íƒ€ì…ì¼ ë•Œ ì‚¬ìš©)
    
    @model_validator(mode='after')
    def validate_query_or_message(self):
        """question, query, message ì¤‘ í•˜ë‚˜ëŠ” í•„ìˆ˜"""
        if not self.question and not self.query and not self.message:
            raise ValueError("question, query ë˜ëŠ” message í•„ë“œ ì¤‘ í•˜ë‚˜ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.")
        return self
    
    def get_query(self) -> str:
        """question, query ë˜ëŠ” message í•„ë“œì—ì„œ ì§ˆë¬¸ì„ ê°€ì ¸ì˜´ (ìš°ì„ ìˆœìœ„: question > query > message)"""
        if self.question:
            return self.question
        if self.query:
            return self.query
        if self.message:
            return self.message
        raise ValueError("question, query ë˜ëŠ” message í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    class Config:
        # ì¶”ê°€ í•„ë“œ í—ˆìš© (ë°±ì—”ë“œ í˜¸í™˜ì„±)
        extra = "allow"


class QueryClassificationResponse(BaseModel):
    """ì§ˆë¬¸ ë¶„ë¥˜ ì‘ë‹µ ëª¨ë¸"""
    action_type: str  # "SQL", "REPORT", "GENERAL_CHAT" ì¤‘ í•˜ë‚˜
    chat_answer: Optional[str] = None  # action_typeì´ GENERAL_CHATì¼ ê²½ìš° ë‹µë³€
    query: Optional[str] = None  # action_typeì´ SQL ë˜ëŠ” REPORTì¼ ê²½ìš° ì›ë³¸/ì •ì œëœ ì§ˆë¬¸
    sql: Optional[str] = None  # ìƒì„±ëœ SQL (SQL/REPORT íƒ€ì…ì— í™œìš©)
    report_html: Optional[str] = None  # Geminiê°€ ìƒì„±í•œ HTML ë³´ê³ ì„œ ë˜ëŠ” ì¶”ê°€ ì•ˆë‚´


class GenerateReportRequest(BaseModel):
    """ë³´ê³ ì„œ ìƒì„± ìš”ì²­ ëª¨ë¸"""
    query: str
    data: str  # DB ì¡°íšŒ ê²°ê³¼ ë°ì´í„° (JSON ë¬¸ìì—´)


class GenerateReportResponse(BaseModel):
    """ë³´ê³ ì„œ ìƒì„± ì‘ë‹µ ëª¨ë¸"""
    report: str  # ìƒì„±ëœ ë³´ê³ ì„œ
    report_html: Optional[str] = None  # ìƒì„±ëœ HTML ë³´ê³ ì„œ


@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "service": "hcManAi",
        "version": "1.0.0",
        "status": "running"
    }


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy"}


@app.post("/generate-sql", response_model=GenerateSQLResponse)
async def generate_sql(request: GenerateSQLRequest):
    """
    SQL ìƒì„± API
    
    RAG íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ì‚¬ìš©ì ì§ˆë¬¸ì„ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    - ì§ˆë¬¸ ìœ í˜• íŒë‹¨ (ìŠ¤í‚¤ë§ˆ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ í™•ì¸)
    - ì…ë ¥ëœ queryë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
    - Vector DBì—ì„œ ìœ ì‚¬í•œ ìŠ¤í‚¤ë§ˆ íŒíŠ¸ ê²€ìƒ‰
    - LLMì— MS-SQL ìƒì„± ìš”ì²­
    """
    if rag_service is None or llm_service is None:
        raise HTTPException(status_code=500, detail="ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    try:
        # 1. ì§ˆë¬¸ ìœ í˜• íŒë‹¨ (ìŠ¤í‚¤ë§ˆ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ í™•ì¸)
        is_schema_query = llm_service.is_schema_related_query(request.query)
        print(f"ğŸ” ì§ˆë¬¸ ìœ í˜• íŒë‹¨: {'ìŠ¤í‚¤ë§ˆ ê´€ë ¨ ì§ˆë¬¸' if is_schema_query else 'ì¼ë°˜ ì§ˆë¬¸'}")
        
        if not is_schema_query:
            # ì¼ë°˜ ì§ˆë¬¸ì´ë©´ íŠ¹ë³„í•œ HTTP ìƒíƒœ ì½”ë“œ ë°˜í™˜ (Javaì—ì„œ ê°ì§€ ê°€ëŠ¥í•˜ë„ë¡)
            print(f"â„¹ï¸  ì¼ë°˜ ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨ë¨. /chat ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            raise HTTPException(
                status_code=400, 
                detail="GENERAL_QUESTION: ì´ ì§ˆë¬¸ì€ ì¼ë°˜ ì§ˆë¬¸ì…ë‹ˆë‹¤. /chat ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
            )
        
        # 2. ìŠ¤í‚¤ë§ˆ ê´€ë ¨ ì§ˆë¬¸ì´ë©´ SQL ìƒì„±
        sql = rag_service.generate_sql(request.query)
        return GenerateSQLResponse(sql=sql)
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì „ë‹¬
        raise
    except Exception as e:
        import traceback
        error_detail = f"SQL ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n{traceback.format_exc()}"
        print(f"âŒ ì—ëŸ¬ ìƒì„¸: {error_detail}")
        raise HTTPException(status_code=500, detail=f"SQL ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@app.post("/summarize", response_model=SummarizeResponse)
async def summarize(request: SummarizeRequest):
    """
    ê²°ê³¼ ìš”ì•½ API
    
    ì§ˆë¬¸ê³¼ DB ì¡°íšŒ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    - LLMì—ê²Œ ì§ˆë¬¸ê³¼ ë°ì´í„°ë¥¼ ì „ë‹¬
    - ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë‹µë³€ ìƒì„±
    """
    if llm_service is None:
        raise HTTPException(status_code=500, detail="LLM ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    try:
        response = llm_service.summarize(request.query, request.data)
        return SummarizeResponse(response=response)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    ì¼ë°˜ ì§ˆë¬¸ ë‹µë³€ API
    
    ìŠ¤í‚¤ë§ˆì™€ ê´€ë ¨ ì—†ëŠ” ì¼ë°˜ì ì¸ ì§ˆë¬¸ì— ëŒ€í•´ Geminië¥¼ í™œìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    - LLMì—ê²Œ ì§ˆë¬¸ì„ ì „ë‹¬
    - ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë‹µë³€ ìƒì„±
    """
    if llm_service is None:
        raise HTTPException(status_code=500, detail="LLM ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    try:
        answer = llm_service.chat(request.question)
        return ChatResponse(answer=answer)
    except Exception as e:
        import traceback
        error_detail = f"ì¼ë°˜ ì§ˆë¬¸ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n{traceback.format_exc()}"
        print(f"âŒ ì—ëŸ¬ ìƒì„¸: {error_detail}")
        raise HTTPException(status_code=500, detail=f"ì¼ë°˜ ì§ˆë¬¸ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@app.post("/query", response_model=QueryResponse)
async def query(request: QueryRequest):
    """
    í†µí•© ì§ˆë¬¸ API
    
    ë°±ì—”ë“œì—ì„œ í•˜ë‚˜ì˜ í˜¸ì¶œë¡œ ì§ˆë¬¸ì„ ë³´ë‚´ë©´, ìë™ìœ¼ë¡œ ì§ˆë¬¸ ìœ í˜•ì„ íŒë‹¨í•˜ì—¬
    ì ì ˆí•œ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    - ìŠ¤í‚¤ë§ˆ ê´€ë ¨ ì§ˆë¬¸: SQL ì¿¼ë¦¬ ìƒì„±
    - ì¼ë°˜ ì§ˆë¬¸: ìì—°ì–´ ë‹µë³€ ìƒì„±
    
    Returns:
        QueryResponse:
            - question_type: "schema" ë˜ëŠ” "general"
            - sql: ìŠ¤í‚¤ë§ˆ ì§ˆë¬¸ì¸ ê²½ìš° ìƒì„±ëœ SQL (ì¼ë°˜ ì§ˆë¬¸ì´ë©´ None)
            - answer: ì¼ë°˜ ì§ˆë¬¸ì¸ ê²½ìš° ìƒì„±ëœ ë‹µë³€ (ìŠ¤í‚¤ë§ˆ ì§ˆë¬¸ì´ë©´ None)
    """
    if rag_service is None or llm_service is None:
        raise HTTPException(status_code=500, detail="ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    try:
        # 1. ì§ˆë¬¸ ìœ í˜• íŒë‹¨
        is_schema_query = llm_service.is_schema_related_query(request.question)
        print(f"ğŸ” ì§ˆë¬¸ ìœ í˜• íŒë‹¨: {'ìŠ¤í‚¤ë§ˆ ê´€ë ¨ ì§ˆë¬¸' if is_schema_query else 'ì¼ë°˜ ì§ˆë¬¸'}")
        
        if is_schema_query:
            # 2-1. ìŠ¤í‚¤ë§ˆ ê´€ë ¨ ì§ˆë¬¸ì´ë©´ SQL ìƒì„±
            sql = rag_service.generate_sql(request.question)
            return QueryResponse(
                question_type="schema",
                sql=sql,
                answer=None
            )
        else:
            # 2-2. ì¼ë°˜ ì§ˆë¬¸ì´ë©´ ë‹µë³€ ìƒì„±
            answer = llm_service.chat(request.question)
            return QueryResponse(
                question_type="general",
                sql=None,
                answer=answer
            )
    except Exception as e:
        import traceback
        error_detail = f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n{traceback.format_exc()}"
        print(f"âŒ ì—ëŸ¬ ìƒì„¸: {error_detail}")
        raise HTTPException(status_code=500, detail=f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@app.post("/classify-query", response_model=QueryClassificationResponse)
async def classify_query(request: ClassifyQueryRequest):
    """
    ì§ˆë¬¸ ë¶„ë¥˜ API
    
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ í–‰ë™ ìœ í˜•ì„ ê²°ì •í•˜ê³ ,
    ì ì ˆí•œ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    - SQL: ë‹¨ìˆœ ë°ì´í„° ì¡°íšŒ ì§ˆë¬¸ â†’ queryì— ì›ë³¸ ì§ˆë¬¸ ë°˜í™˜
    - REPORT: ë¶„ì„/ë³´ê³ ì„œê°€ í•„ìš”í•œ ë³µí•© ì§ˆë¬¸ â†’ ë³´ê³ ì„œ ìƒì„± í›„ chat_answerì— ë°˜í™˜
    - GENERAL_CHAT: ì¼ë°˜ ëŒ€í™” ì§ˆë¬¸ â†’ chat_answerì— ë‹µë³€ ë°˜í™˜
    
    Returns:
        QueryClassificationResponse:
            - action_type: "SQL", "REPORT", "GENERAL_CHAT" ì¤‘ í•˜ë‚˜
            - chat_answer: action_typeì´ GENERAL_CHAT ë˜ëŠ” REPORTì¼ ê²½ìš° ë‹µë³€/ë³´ê³ ì„œ
            - query: action_typeì´ SQL ë˜ëŠ” REPORTì¼ ê²½ìš° ì›ë³¸/ì •ì œëœ ì§ˆë¬¸
    """
    if rag_service is None or llm_service is None:
        raise HTTPException(status_code=500, detail="ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    try:
        # query ë˜ëŠ” message í•„ë“œì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
        user_query = request.get_query()
        print(f"ğŸ“¥ classify-query ìš”ì²­ ìˆ˜ì‹ : query={user_query}")
        
        # 1. ì§ˆë¬¸ ë¶„ë¥˜
        classification = llm_service.classify_query(user_query)
        action_type = classification.get("action_type", "GENERAL_CHAT")
        print(f"ğŸ” ì§ˆë¬¸ ë¶„ë¥˜ ê²°ê³¼: {action_type}")
        
        # 2. action_typeì— ë”°ë¥¸ ì²˜ë¦¬
        if action_type == "GENERAL_CHAT":
            # ì¼ë°˜ ëŒ€í™” ì§ˆë¬¸: ì´ë¯¸ chat_answerê°€ í¬í•¨ë˜ì–´ ìˆìŒ
            chat_answer = classification.get("chat_answer")
            if not chat_answer:
                # chat_answerê°€ ì—†ìœ¼ë©´ ìƒì„±
                chat_answer = llm_service.chat(user_query)
            
            return QueryClassificationResponse(
                action_type=action_type,
                chat_answer=chat_answer,
                query=None
            )
        
        elif action_type == "SQL":
            query_text = classification.get("query", user_query)
            print("ğŸ“ SQL ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘...")
            generated_sql = rag_service.generate_sql(query_text)
            data = request.data
            
            if data:
                print(f"ğŸ“Š SQL ê²°ê³¼ ë°ì´í„° ì œê³µë¨ (ê¸¸ì´: {len(data)}). ìš”ì•½ ìƒì„± ì¤‘...")
                summary = llm_service.summarize(query_text, data)
                print("âœ… SQL ê²°ê³¼ ìš”ì•½ ìƒì„± ì™„ë£Œ")
                return QueryClassificationResponse(
                    action_type=action_type,
                    chat_answer=summary,
                    query=query_text,
                    sql=generated_sql
                )
            else:
                guidance = (
                    "SQLì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ë¨¼ì € ì•„ë˜ SQLì„ ì‹¤í–‰í•˜ì—¬ ì–»ì€ ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ "
                    "'data' í•„ë“œì— ë‹´ì•„ ë‹¤ì‹œ ìš”ì²­í•´ì£¼ì‹œë©´ ìš”ì•½ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
                return QueryClassificationResponse(
                    action_type=action_type,
                    chat_answer=guidance,
                    query=query_text,
                    sql=generated_sql
                )
        
        elif action_type == "REPORT":
            # REPORT ì§ˆë¬¸: ë¨¼ì € SQLì„ ì œê³µí•˜ê³ , ë°ì´í„°ê°€ ìˆìœ¼ë©´ HTML ë³´ê³ ì„œ ìƒì„±
            query_text = classification.get("query", user_query)
            
            print(f"ğŸ“Š ë³´ê³ ì„œ ìƒì„±ì„ ìœ„í•œ SQL ìƒì„± ì¤‘...")
            sql = rag_service.generate_sql(query_text)
            print(f"ğŸ“ ìƒì„±ëœ SQL: {sql}")
            
            data = request.data
            print(f"ğŸ” ë°ì´í„° í™•ì¸: data ì œê³µ ì—¬ë¶€={data is not None}")
            if data:
                print(f"ğŸ“Š ë°ì´í„° ê¸°ë°˜ ë³´ê³ ì„œ ìƒì„± ì¤‘... (ë°ì´í„° í¬ê¸°: {len(data)} ë¬¸ì)")
                report_text, html_report = llm_service.generate_report(query_text, data)
                print(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: ë³´ê³ ì„œ ê¸¸ì´={len(report_text)} ë¬¸ì")
                print(f"ğŸ” ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°: {report_text[:200]}...")
                
                response = QueryClassificationResponse(
                    action_type=action_type,
                    chat_answer=report_text,
                    query=query_text,
                    sql=sql,
                    report_html=html_report
                )
                print(f"ğŸ” ì‘ë‹µ ê°ì²´ ìƒì„± ì™„ë£Œ: HTML ê¸¸ì´={len(html_report) if html_report else 0}")
                return response
            else:
                guidance = (
                    "ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ë ¤ë©´ ì•„ë˜ SQLì„ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë§Œë“  ë’¤ "
                    "'data' í•„ë“œì— ë‹´ì•„ ë‹¤ì‹œ ìš”ì²­í•´ì£¼ì„¸ìš”."
                )
                return QueryClassificationResponse(
                    action_type=action_type,
                    chat_answer=guidance,
                    query=query_text,
                    sql=sql
                )
        
        else:
            # ì˜ˆìƒì¹˜ ëª»í•œ action_type
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” action_type: {action_type}")
            
    except Exception as e:
        import traceback
        error_detail = f"ì§ˆë¬¸ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n{traceback.format_exc()}"
        print(f"âŒ ì—ëŸ¬ ìƒì„¸: {error_detail}")
        raise HTTPException(status_code=500, detail=f"ì§ˆë¬¸ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@app.post("/generate-report", response_model=GenerateReportResponse)
async def generate_report(request: GenerateReportRequest):
    """
    ë³´ê³ ì„œ ìƒì„± API
    
    ì§ˆë¬¸ê³¼ DB ì¡°íšŒ ê²°ê³¼ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ Gemini ë¶„ì„ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬
    ìƒì„¸í•œ ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    - ì§ˆë¬¸ê³¼ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
    - íŠ¸ë Œë“œ, íŒ¨í„´, ë¹„êµ ë¶„ì„ í¬í•¨
    - ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë³´ê³ ì„œ ìƒì„±
    - Geminiì—ê²Œ Google Slides URL ìš”ì²­ (ì‹¤ì œ íŒŒì¼ì´ ì•„ë‹ ìˆ˜ ìˆìŒ)
    
    Returns:
        GenerateReportResponse:
            - report: ìƒì„±ëœ ìš”ì•½ í…ìŠ¤íŠ¸
            - report_html: Geminiê°€ ìƒì„±í•œ HTML ë³´ê³ ì„œ (ì„ íƒì‚¬í•­)
    """
    if llm_service is None:
        raise HTTPException(status_code=500, detail="LLM ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    try:
        print(f"ğŸ“Š ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        print(f"ğŸ“ ì§ˆë¬¸: {request.query}")
        print(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {len(request.data)} ë¬¸ì")
        
        report, html_report = llm_service.generate_report(request.query, request.data)
        print(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: ê¸¸ì´={len(report)} ë¬¸ì")
        
        return GenerateReportResponse(report=report, report_html=html_report)
    except Exception as e:
        import traceback
        error_detail = f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n{traceback.format_exc()}"
        print(f"âŒ ì—ëŸ¬ ìƒì„¸: {error_detail}")
        raise HTTPException(status_code=500, detail=f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host=settings.API_HOST,
        port=settings.API_PORT,
        reload=True
    )

